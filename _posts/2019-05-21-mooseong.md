# 소개 Learning to Make Analogies by Contrasting Abstract Relational Structure



얼마전 바벨봇 스터디에서 리뷰한 딥마인드 논문을 소개해드리겠습니다. 



뉴랄넷이 Analogy를 익힐 수 있는가? 신경망이 학습 데이터랑 비슷한 상황에서만 잘 하고, 보지 못했던 데이터에서는 일반화 어렵지 않나? 그냥 외우고 있는거 아닌가? 인간이 가진 '유추' 능력을 가질 수는 있나? 라는 인지과학자들의 지적에 대해 대응하고 싶어하는 내용입니다. 저자들이 이런거 몇개 냈습니다. 예전에 딥러닝용 지능검사 비슷한거 만들고(추상화 능력이 있니?), 가장 최근엔 수리추론용 검사를 만들었죠.



이번 논문에선  '유추' 능력을 테스트할 수 있는 딥러닝용 과제를 만들었습니다.  

시각적 유추를 하는 테스트에요. 제가 첨부한 그림 1을 보시면, 맨 윗줄에 그림 3개가 나옵니다. 원 모양이 하나씩 증가하고 있죠? 그리고 밑에가 테스트용입니다. 선이 하나 나오는데 점점 색깔이 진하게 되야 합니다. 물음표 모양에 뭐가 나와야 하는지, 후보군 4개 주고 고르게 하는 아이큐 검사 비슷한 것입니다. 삼성직무검사에도 이런 도형 추론 같은게 있죠.



심리학 이론 중 '유추'에 대한 주요 이론이 2개 정도 있다고 하네요. 거기에 영감을 얻어서, '유추'란 대상의 유사성(속성의 공유 수가 많은 것)이 아니라 관계성을 추론해야 한다. 와, 표상과 추론이 계속 상호작용하는 형태로 유추가 일어난다. 라는 내용을 참조했다고 합니다. 



이런 형태로 계속 학습을 시키고, 그 뒤에 테스트를 해서 얼마나 맞추는지 보았습니다. 결론은 - 어떤 구조의 뉴랄넷을 쓰느냐가 핵심이 아니라, 학습 시킬 때 어떤 식으로 데이터를 제시할 것인지 - 학습 방식의 설계가 더 중요했다라고 합니다. 



즉 간단한 CNN-RNN 기본 구조로 하나, ResNet이나 Relation Network 같은 이후에 좀 파워가 올라가거나 관계 추론에 더 특화되어 있는 모형을 쓰나. 성능 차이가 없었죠.  



그 보다는 제가 첨부한 2번째 그림인 '그림 3'처럼 Learning by contrasting으로 학습시켜야 한다고 합니다. 이게 뭐냐? 방법은 쉽습니다. '그림 3'의 d (하단 오른쪽)를 보시면 



'자 정답이 뭐지?'라고 제시할 때 오답들을 하나는 랜덤하게 섞어서 만들어준다면, Learning by contrasting은 오답들도 '가능한 관계' 중에 하나에서 택해서 준다는거죠. 즉 뉴랄넷이 제시된 후보답들을 비교해서 '유추'에 필요한 관계 표상을 더 잘 배울 수 있다고 말합니다. 

(결과는 마지막에 첨부한 맨 오른쪽 사진 '그림 4'가 자기들 방식이 더 성능이 좋다고 말합니다)



아무튼, 딥마인드는 <이렇게 간단한 뉴랄넷도 '유추'를 배울 수 있는 잠재력이 있어>라고 논문에서 보여주고 있습니다. 그리고 '유추'를 사람처럼 할 수 있도록 좀 더 연구를 집중해보면, 사람같은 기계를 만들 수 있을꺼야 - 라고 결론 내리고 있습니다.



딥마인드의 '일반 지능' 관련 연구 중에 하나 입니다. 아직 갈길이 먼 비실용적으로 보이는 연구지만, 저는 재밌더라구요. 



일단 논문은 ICLR 2019년 학회에 통과되었습니다. 머신러닝 관점에서는 나름 설득력이 있었나봐요. 인지과학쪽으로는 어떨지 모르겠습니다. 

오픈리뷰 넷의 피어리뷰들도 매우 읽어볼만합니다. 

\- https://openreview.net/forum?id=SylLYsCcFm



————————



초록 



Analogical reasoning has been a principal focus of various waves of AI research. Analogy is particularly challenging for machines because it requires relational structures to be represented such that they can be flexibly applied across diverse domains of experience. Here, we study how analogical reasoning can be induced in neural networks that learn to perceive and reason about raw visual data. We find that the critical factor for inducing such a capacity is not an elaborate architecture, but rather, careful attention to the choice of data and the manner in which it is presented to the model. The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains, a training method that uses only the input data to force models to learn about important abstract features. Using this technique we demonstrate capacities for complex, visual and symbolic analogy making and generalisation in even the simplest neural network architectures.

( 구글 : 

유 추한 추론은 AI 연구의 다양한 물결의 주요 초점이었습니다. 유추는 다양한 경험 영역에 유연하게 적용될 수 있도록 관계형 구조가 표현되어야하기 때문에 컴퓨터에서 특히 어려운 작업입니다. 여기에서는 원시 시각적 데이터를 감지하고 추론하는 방법을 배우는 신경 네트워크에서 유추 추론을 유도 할 수있는 방법을 연구합니다. 우리는 그러한 용량을 유도하는 데 결정적인 요소가 정교한 아키텍처가 아니라 데이터의 선택과 모델에 제시되는 방식에주의를 기울이는 것으로 나타났습니다. 유추 추론을위한 가장 강력한 용량은 네트워크가 입력 영역에서 추상 관계형 구조를 대조하여 유추를 학습 할 때 발생합니다. 입력 데이터만으로 모델에 중요한 추상적 기능을 학습하게하는 교육 방법입니다. 이 기법을 사용하여 우리는 가장 단순한 신경 네트워크 아키텍처에서도 복잡하고 시각적이며 상징적 인 비유 만들기 및 일반화 능력을 보여줍니다.)





# Neural ODE



https://youtu.be/oIa3BFBHJFI



안녕하세요!!!



Neural ODE는 지금 전세계적으로 선풍적인 인기를 끌고있는데요!



Neural ODE란 신경망과 상미분방정식을 접목한 모델입니다!

두달동안 논문을 봤더니

만끽이 이렇게 완벽한 이해는 여전히 못했습니다

WA!

Neural ODE를 하루에 25분만 투자한다면

Resnet 1시간,



여러분도 하루에 25분만,

Neural ODE의 세계로 들어가 봅시다!



NODE NODE NODE Norm Flow!

NODE NODE NODE Norm Flow!

NODE NODE NODE Norm Flow!



네.. 트위치 스트리머 만끽입니다 오늘 읽어볼 논문은 Augmented Neural ODE 입니다

4월초에 arxiv에 올라온 따끈한 논문입니다



논문 읽기에 앞서! 오늘은 NIPS 2018에서 Best Paper를 받아 전세계적으로 선풍적인 인기를 끌었던 Neural ODE에 대한 설명부터 드리고 시작할 예정입니다.



저희 연구실에서 진행중인 Various Neural Network Study (전형적인 CNN, RNN 외에 Neural Net에 적용되고 있는 다양한 ML 기법들을 공부하는 스터디)에서 준비했던 발표자료를 통해 설명드릴 예정입니다.



Slide: https://bit.ly/2GMTvMg

Twitch: https://www.twitch.tv/profitcastle



오늘 방송은 5시부터 시작 예정입니다 :)



# skip-gram

중심 단어로 주변 단어를 예측



# 잡담

\#잡담 정통 심리학 : 더 높이 더 낮게 - 빠르고 느리게 가는 법.



오랜만의 잡담입니다. 요새 '볼츠만의 원자'라는 책을 읽고 있습니다. 재밌습니다. 특히, '원자'라는 것이 실제 존재하는지에 대한 의견 대립이 있던 시절 물리학자들의 이야기와, 그 당시 핫한 발견과 접근이 집결된 '열의 기체 운동론'을 둘러싼 논쟁과 노력들이 시대상과 함께 잘 쓰여져 있습니다. 



시대의 발전에 맞춰서 물리학이 자신들의 정체성을 고쳐나가는 것을 보면서, 요즘의 심리학에 대해서도 생각해봅니다. 심리학자들이 만든 연결주의가 딥러닝이란 이름으로 부활하고, 학습이란 무엇인지, 지능이란 무엇인지를 고민하며 - 사람을 닮은 가상의 존재를 만들어놓고 - 이건 진짜 '인간'과는 다르게 작동하느니 마느니 논쟁이 벌어지고 있는 이때에 말이죠.



많은 분들이 잊고 있거나 일종의 농담으로 치부하고 넘어가시겠지만, 저는 정말 진지하게 싸이그래머가 정통 심리학 그룹이라고 생각하고 있습니다. 적어도 그렇게 되었으면 합니다. 



하지만 지금 여기서 스터디하고 있는 것들이 정말 심리학일까? 라고 의구심을 가지신 분들이 많을 것입니다. 저도 쌓여가는 글과 사진, 공유된 링크들을 보면서 가끔 '어? 여긴 어디지?'라는 생각을 하게 될때가 있어요.



그러다 '볼츠만의 원자' 책을 보면서 제가 제 시대의 올드한 심리학을 배웠고, 시대는 변하고 뭔가 지각 변동이 일어나고 있는데 그게 무엇인지 몰라서 그런 '불투명함'을 받아들이기 힘들어한다는 것을 깨달았습니다. 물론 그 '불투명함'을 투명하게 만들고 새 방법론과 정체성을 확립해주는 역할은 저의 몫은 아니겠지요. 최신의 젊은 심리학 연구자들이 열심히 '역사의 승자'가 되기 위해 싸우고 있음을 늘 믿습니다. 



\* 

그렇습니다. 심리법칙의 물리학을 기다리고 있습니다. 현재의 구시대적 심리학 연구들이 제 소명을 다하면, 그간 남겨놓은 데이터들을 바탕으로  어떤 천재가 그 작은 구슬들을 이어내는 강건하고 아름다운 법칙을 만들어낼 날이 오겠죠. 



아마 지금의 심리학보다, 

더 높이 

\- 계산모델링을 강건하게 매크로한 레벨에서 결합하여 사회적 맥락을 인자로 받아 집단안의 개인을 예측해내는 방향으로 가던가

혹은 더 낮게 

\- 뉴론들의 신호다발까지 내려가서 차근차근 수리정보적 토대로 심리법칙들을 재구성하고 검증하는 방향으로 가던가

두 가능성이 있을 것 입니다. 



쉽게 말해 <코딩하거나 뇌를 보거나>. 

심리학도에게 남은 길은 이것이고, 혹시 이 둘을 피하려고 한다면 철학이 점점 특수한 영역으로 쪼그라들어 비판자 역할만을 남겨놓은 것처럼 - 인문교양화되는 방향만이 남겠죠. 한때 심리학이라고 생각했던 것들은 그 잔여물들을 종교의 영역으로 밀어넣게 될지도 모릅니다. 



물론 인간을 측정하는 데이터 도구들과 재료들이 넘쳐나고 온라인의 삶이 오프라인의 삶과 비교해서 그 중요도와 절대체류 시간을 앞서는 앞으로의 세계에서 언제나 심리학은 중요하겠지만 - 그것을 심리학에서만 하라는 보장은 없을거라고 생각합니다. 모든 것에 심리학이 할 수 있다는 것과 그 영역들에서 심리학만 특히 잘할 수 있다는 것은 같은 얘기가 아닐테니까요.



\* 

높고 낮게 가기 위해서는 - 빨리 가거나 늦게 갈 수 있습니다. 

소프트웨어의 형태로 빠르게 검증하며 빨리 갈 수 있고

\- 컴공에 가까워지겠죠. 좀 더 빠르게 산업화되고 좀 더 빨리 돈을 벌 수 있고 좀 더 빨리 효용을 증명할 수 있을 것입니다. 다만 우선순위는 진리보다는 효율이 지배하는 영역에서 살아남아야 합니다 

뇌과학에 강건하게 결합되는 형태로 느리게 갈 수 있을 것 입니다

\- 의학의 한 형태로 응용될 것이고 결국 최종 진리 증명은 이쪽을 거쳐야 하니까 최후의 영광은 이쪽의 방향이겠죠. 하지만 매우 느리게 변하고 좁은 인적 네트워크를 지닌 과학자들의 영역에서 우선 증명하고 대중에게 길게 오해받는 일을 반복하게 될 것입니다



저는 애호가니까, 그런 과정을 주변에서 지켜보며 그 관련 도구들을 실험해보는 일을 해나갈테지만, 언젠가 심리의 물리학이 완성되는 날이 와서, 싸이그래머에서의 시도들이 '정말 정통 심리학이었어'라고 말하게 되길 바래봅니다. 



\* 

결론: 뜬금없지만 - 올해 중반기부터는 정통..심리학 그룹에서, 정통 심리학 그룹이 되기 위해 본격적인 작업들을 해나갈 생각입니다. 도구를 쓰는 이유 - 즉 탐험의 대상을 더 강조해볼까합니다 : '지능, 정서, 성격, 언어, 자아, 관계, 대화, 협력, 행복, 올바른 판단이란 무엇인가'



————————————



<오늘날 우리는 관찰하거나 검출할 수 있는 모든 현상을 쿼크, 광자, 전자기장, 굽은 공간처럼 동떨어지고 눈으로 볼 수도 없는 것으로 설명하는데 익숙해져 있지만, 200년 전의 과학자들은 여전히 자신들이 직접 보거나 측정할 수 있는 것에만 관심을 가지고 있었다. 그런 뜻에서 손가락으로도 느낄 수 있는 열은 의심할 여지가 없는 물리학적 현상이었다. 풍선의 팽팽한 정도나 증기기관 피스톤의 강력한 충격으로 느낄 수 있는 기체의 압력도 마찬가지였다. 



그렇게 직접적이고 확실하게 느낄 수 있는 것을 눈으로 볼 수도 없는 존재의 느낄 수 없는 움직임으로 설명하는 것이 무슨 의미가 있겠는가? 작은 원자들이 집단적으로 충돌해서 피스톤을 밀어낼 정도의 힘을 발휘한다고 상상할 수는 있겠지만, 그렇게 생각해서 무엇을 얻을 수 있겠는가?



명백하게 실재하는 것을 인간의 눈에서 영원히 감추어져 있는 '원자'로 설명하려는 것은 잘못된 설명이라고 여겼다.>



<한동안 아무도 그런 회의적인 지적에 대해서 반박을 하지 못했다. 그러나 원자론을 믿는 사람들은 원자론을 근거로 한 이론이 궁극적으로 실험에서 유추한 경험법칙에 만족하거나, 아니면 아예 설명을 포기해버리는 것보다는 더 완전하고, 포괄적이고, 학술적으로 더 만족스러운 수준으로 발전할 것이라고 생각하거나 그렇게 믿어버렸다. 그러나 새로운 모습을 드러내고 있던 그런 사고방식은 당시의 물리학자들에게는 여전히 생소한 것이었다. 물리학은 전통적으로 기체의 온도와 압력 사이의 관계를 나타내는 법칙처럼 직접 측정할 수 있는 현상들 사이의 정량적인 관계를 찾아내는 것을 목적으로 하고 있었다. 그런 수준을 넘어서, 관찰할 수는 없지만 '존재'할 것을 추측되는 양을 이용해서 실험에서 관찰되는 사실들을 설명하려는 시도는 대부분의 물리학자들이 자신들의 범위라고 믿었던 한계를 벗어나는 것이었다.



19세기 후반에 일어나고 있었던 변화는 실험 물리학과 밀접하게 관련되어 있으면서도(아니면 그렇게 되길 바라면서) 실제로는 실험 물리학과 분명하게 구별되는, 오늘날 우리가 이론 물리학이라고 부르는 그 자체로 독립된 새로운 분야의 탄생이었다. 



물리학의 이론이 사실이나 관찰과 관계를 가지고 있으면서도 이론의 범주 안에서만 진정한 정의를 찾을 수 있는 구조로 구축된 독자적인 지식구조라는 생각은 당시에는 쉽게 이해할 수 없는 혁신적인 것이었다.>



_데이비드 린들리, "볼츠만의 원자"



# 딥마인드

\#소개 Reinforcement Learning, Fast and Slow



\* 링크 - https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0



딥마인드가 강화학습에서 일어나고 있는 최신의 시도들을 ㅡ 특히 인지과학의 인사이트를 결합하려는 자신들의 연구방향을 정리하는 논문을 썼습니다. 그리고 뇌과학과 심리학에 도움도 될거야라면서 어필도 하구요.



“Implications for Neuroscience and Psychology”라고 아예 소제목으로 한꼭지 할당까지 하면서 말이죠.



딥마인드가 이렇게까지 구애를 하는데,심리학도여 강화학습 공부에 좀 투자해봅시다.



# the power of self-learning

\#소개 The Power of Self-Learning Systems



\* 링크 - https://youtu.be/3N9phq_yZP0



오랜만에 딥마인드 소식입니다. MIT에서 딥마인드의 하사비스가 강연한 내용입니다. 최근의 알파- 시리즈에 대해 얘기하고 있습니다. 

\* AlphaZero - 바둑. 완전정보, self-learning

\* AlphaStar - 실시간 불완전 정보, 전략게임

\* AlphaFold - 단백질 구조 예측



중간중간 시스템 소개도 하고 있고, 딥마인드의 철학 얘기도 하고 있습니다(하사비스가 늘 얘기하고 다니죠)



개인적으론, 하사비스를 초청한 MIT의 센터 이름이 눈에 띄네요.



The Center for Brains, Minds and Machines (CBMM)

(센터 링크는 여기 - https://cbmm.mit.edu/ )









하사비스 강연 영상 보다가, 하사비스 초청한 MIT 센터의 여름 강좌 코스가 꽤 좋다는걸 알았습니다.



\* 작년 썸머스쿨 자료들 - 

https://cbmm.mit.edu/summer-school/2018/resources



2019년에 다룬다는 내용들이 다음과 같습니다.



BRAINS, MINDS & MACHINES SUMMER COURSE 2019

\* https://cbmm.mit.edu/summer-school/2019



The class discussions will cover a range of topics, including:



\- Neuroscience: neurons and models

\- Computational vision

\- Biological vision

\- Machine learning

\- Bayesian inference

\- Planning and motor control

\- Memory

\- Social cognition

\- Inverse problems & well-posedness

\- Audition and speech processing

-Natural language processing



늘 싸이그래머에서 해왔던 스터디죠. 현재 우리나라 인지과학 과정, 코스, 커리큘럼들이 저런 것들을 다루고 있습니다.



물론 싸이그래머는 학교가 아니니까, 깊게는 못다루고 - 저 내용들에 해당하는 '기술 스택'이라는 관점에서 한번 'Ψ스택 '이라는 이름으로 스터디를 진행해도 좋을 것 같아요. 대략 파이썬, 컴퓨터 비전, 머신러닝, 딥러닝, 베이지안, 뉴로이미징, 뉴랄데이터 처리, 시계열 분석, 오디오처리, 자연어처리. 이런쪽의 스킬셋들을 코딩 위주로 가볍게 체험해보는 정도겠죠? 바벨피쉬의 기술스택 스터디인 바벨스택처럼 말이죠.

